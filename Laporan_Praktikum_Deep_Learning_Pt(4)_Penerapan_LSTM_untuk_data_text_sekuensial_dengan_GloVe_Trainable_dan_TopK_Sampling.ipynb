{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "71616d1f",
      "metadata": {
        "id": "71616d1f"
      },
      "source": [
        "# **LAPORAN PRAKTIKUM**\n",
        "*Laporan diperuntukan sebagai pemenuh syarat penilaian praktikum mata kuliah Deep Learning*\n",
        "\n",
        "```\n",
        "Dosen Pengampu : Sevi Nurafni\n",
        "Oleh : Catherine V. Pang 2C2220008 VI/A\n",
        "Hari, Tanggal: Selasa, 15 April 2025\n",
        "Pertemuan Ke: 4\n",
        "Topik: Penerapan LSTM Untuk Data Sekuensial (Prediksi Kata Menggunakan LSTM)\n",
        "Tugas: Modifikasi Model LSTM\n",
        "Pengerjaan: Penerapan LSTM GloVe Trainable dan top-k sampling untuk memodifikasi model LSTM awal.\n",
        "PROGRAM STUDI S1 SAINS DATA FAKULTAS SAINS DAN TEKNOLOGI UNIVERSITAS KOPERASI INDONESIA 2025\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kdcY6fYpiAbM",
      "metadata": {
        "id": "kdcY6fYpiAbM"
      },
      "source": [
        "#**TEORI PENGANTAR, CONTOH MODEL & TUGAS**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PSOMbCueiAbN",
      "metadata": {
        "id": "PSOMbCueiAbN"
      },
      "source": [
        "### LSTM\n",
        "\n",
        "\n",
        "**LSTM** (Long Short-Term Memory) adalah jenis jaringan saraf tiruan yang digunakan untuk menganalisis data berurutan, seperti:\n",
        "\n",
        "- Kalimat (teks)\n",
        "- Suara (audio)\n",
        "- Sensor (waktu)\n",
        "\n",
        "\n",
        "K**enapa Butuh LSTM?**\n",
        "\n",
        "Model biasa (seperti yang pakai Dense layer) tidak ingat urutan. Padahal, dalam kalimat atau suara, urutan sangat penting:\n",
        "\n",
        "Contoh:\n",
        "\n",
        "> “saya makan nasi” ✅ \\\n",
        "> “nasi makan saya” ❌ (urutan kacau)\n",
        "\n",
        "LSTM membantu menghafal informasi penting dari urutan sebelumnya, lalu menggunakannya untuk membuat prediksi."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 1 - LSTM sederhana"
      ],
      "metadata": {
        "id": "NKc7XbYBW-1H"
      },
      "id": "NKc7XbYBW-1H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ilRsEItMiAbN",
      "metadata": {
        "id": "ilRsEItMiAbN"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "\n",
        "Diceritakan terdapat seekor kancil yang sombong karena kemampuan berlarinya dan mengajak kura-kura untuk melakukan lomba lari dengannya.\n",
        "Dengan rendah hati dan percaya diri, kura-kura pun menerima ajakan kancil.\n",
        "Keesokan paginya, keduanya menuju kawasan hutan tempat lomba lari.\n",
        "Sesuai dengan perkiraan si kancil, ia berhasil lari dengan sangat cepat dan mengalahkan kura-kura yang tertinggal di belakang.\n",
        "Namun, ketika kancil mendekati garis finish, ia memutuskan untuk istirahat di bawah pohon rindang karena beranggapan bahwa\n",
        "lawannya itu masih sangat lama tiba. Sampai akhirnya si kancil tertidur pulas dan tidak menyadari bahwa kura-kura telah lebih dulu\n",
        "sampai digaris finish. Dari dongeng di atas, pesan moral yang bisa diajarkan pada si Kecil adalah untuk tetap rendah diri mau sehebat apapun dirinya.\n",
        "Selain itu, anak juga diajarkan untuk tidak meremehkan kemampuan orang lain dengan kemampuannya.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QHsjBPrSiAbO",
      "metadata": {
        "id": "QHsjBPrSiAbO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9PrQsCkuiAbP",
      "metadata": {
        "id": "9PrQsCkuiAbP"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "sequences = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(1, len(sequences)):\n",
        "    X.append(sequences[:i])\n",
        "    y.append(sequences[i])\n",
        "\n",
        "X = pad_sequences(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SLGiKGAeiAbP",
      "metadata": {
        "id": "SLGiKGAeiAbP"
      },
      "source": [
        "- `Tokenizer`: Mengubah kata menjadi angka (token).\n",
        "- `texts_to_sequences`: Mengubah teks menjadi deretan angka (berdasarkan kata).\n",
        "- `pad_sequences`: Membuat semua input memiliki panjang yang sama.\n",
        "- `Loop for`: Membuat data input dan target. Misalnya, [\"saya\"] → [\"suka\"], [\"saya\", \"suka\"] → [\"belajar\"]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7cebf61",
      "metadata": {
        "id": "a7cebf61"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6OuQA-OgICB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "a6OuQA-OgICB",
        "outputId": "18b26a10-574b-44ea-dba0-0cd8f7c20e61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=10))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(len(tokenizer.word_index)+1, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JvEIMiC2iAbQ",
      "metadata": {
        "id": "JvEIMiC2iAbQ"
      },
      "source": [
        "- `Embedding`: Layer yang mengubah angka token menjadi vektor fitur.\n",
        "- `LSTM(50)`: Layer LSTM dengan 50 unit.\n",
        "- `Dense(...)`: Layer output dengan aktivasi softmax → memilih kata berikutnya.\n",
        "- `compile`: Menyiapkan model untuk dilatih, menggunakan loss dan optimizer yang sesuai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NamZtXJ_iAbQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NamZtXJ_iAbQ",
        "outputId": "94655622-86c2-4d8c-93fa-2fb22ef06bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.0025 - loss: 4.5437\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.0755 - loss: 4.5386\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.0869 - loss: 4.5308\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.0600 - loss: 4.5104\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.0617 - loss: 4.4601\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.0565 - loss: 4.4199\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.0695 - loss: 4.3846\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.0491 - loss: 4.4211\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.0669 - loss: 4.3622\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.0652 - loss: 4.3753\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.0565 - loss: 4.3471\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.0808 - loss: 4.3301\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0669 - loss: 4.3231\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.0574 - loss: 4.3349\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.0803 - loss: 4.2723\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.0591 - loss: 4.3204\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0536 - loss: 4.2794\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0617 - loss: 4.2650\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.0543 - loss: 4.2336\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0448 - loss: 4.2982\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.0665 - loss: 4.1696\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.0794 - loss: 4.1511\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.0638 - loss: 4.1285\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.0738 - loss: 4.1005\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.0704 - loss: 4.0961\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.0785 - loss: 4.0046\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.0676 - loss: 4.0047\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.0589 - loss: 3.9751\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.0547 - loss: 3.9841\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0652 - loss: 3.8805\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.0948 - loss: 3.8547\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0829 - loss: 3.8287\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.0598 - loss: 3.7647\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.0640 - loss: 3.7617\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0765 - loss: 3.7110\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.0576 - loss: 3.6516\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.0822 - loss: 3.6016\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.1084 - loss: 3.5297\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.0738 - loss: 3.5487\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.0907 - loss: 3.5280\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.1260 - loss: 3.4438\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.0979 - loss: 3.4644\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.1214 - loss: 3.4385\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.1270 - loss: 3.3656\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.0992 - loss: 3.3544\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.0849 - loss: 3.3213\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.1617 - loss: 3.1982\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.1488 - loss: 3.1990\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1489 - loss: 3.1161\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.1514 - loss: 3.1230\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.1512 - loss: 3.0841\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.1543 - loss: 3.0351\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.1460 - loss: 3.0145\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.1442 - loss: 2.9728\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.1511 - loss: 2.9397\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.1497 - loss: 2.9246\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.1956 - loss: 2.8383\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.1387 - loss: 2.8500\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.1746 - loss: 2.7441\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.1727 - loss: 2.7436\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.1688 - loss: 2.7378\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.2161 - loss: 2.6547\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.1884 - loss: 2.6561\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.2704 - loss: 2.6209\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2474 - loss: 2.6190\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.2287 - loss: 2.5584\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.2245 - loss: 2.5580\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.2152 - loss: 2.5127\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.1892 - loss: 2.5390\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.1982 - loss: 2.4799\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2340 - loss: 2.4601\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.2320 - loss: 2.4272\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.2810 - loss: 2.3933\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3122 - loss: 2.3374\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3142 - loss: 2.3246\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2912 - loss: 2.3355\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2671 - loss: 2.3407\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.3004 - loss: 2.2587\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.2969 - loss: 2.2545\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.2950 - loss: 2.2484\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.3142 - loss: 2.2467\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.3159 - loss: 2.1898\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.3331 - loss: 2.2130\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.3187 - loss: 2.1636\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.3336 - loss: 2.1374\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3222 - loss: 2.1717\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.3416 - loss: 2.1317\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.2951 - loss: 2.0796\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.2792 - loss: 2.0754\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.3386 - loss: 2.0807\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.3184 - loss: 2.0686\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.3301 - loss: 2.0351\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3376 - loss: 2.0308\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2831 - loss: 2.0182\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3147 - loss: 2.0023\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3200 - loss: 2.0038\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3312 - loss: 1.9954\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3499 - loss: 1.9646\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.4445 - loss: 1.9174\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4142 - loss: 1.9554\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a20c9bf4f50>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X, y, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zkIP4mE4iAbR",
      "metadata": {
        "id": "zkIP4mE4iAbR"
      },
      "source": [
        "- `fit`: Melatih model dengan data X dan y selama 500 kali.\n",
        "- `verbose=1`: Menampilkan output proses training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Nw2Ghgd2iAbR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw2Ghgd2iAbR",
        "outputId": "ecfe2740-bdee-46ca-edd4-0a023e5c5724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi kata berikutnya: kemampuan\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Kura-kura dan Kancil\"\n",
        "tokens = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "tokens = pad_sequences([tokens], maxlen=X.shape[1])\n",
        "\n",
        "predicted = model.predict(tokens, verbose=0)\n",
        "predicted_word_index = np.argmax(predicted)\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "        print(\"Prediksi kata berikutnya:\", word)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tdkBVnfuiAbR",
      "metadata": {
        "id": "tdkBVnfuiAbR"
      },
      "source": [
        "- `texts_to_sequences`: Mengubah teks input menjadi token angka.\n",
        "- `pad_sequences`: Menyamakan panjang input dengan data training.\n",
        "- `predict`: Model memprediksi token berikutnya.\n",
        "- `np.argmax`: Mengambil indeks (token) dengan probabilitas tertinggi.\n",
        "- `Loop for`: Mencari kata dari indeks token hasil prediksi."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4DSPJuZLi2cW",
      "metadata": {
        "id": "4DSPJuZLi2cW"
      },
      "source": [
        "**Tugas:**\n",
        "\n",
        "Hasil dari model di atas masih buruk dapat dilihat dari hasil prediksi yang tidak make sense berarti model belum mengenali pola. Lakukan eksperimen dan evaluasi dari model LSTM di atas sehingga mennghasilkan akurasi dan prediksi yang baik. Kemudian jelaskan bagaimana cara kerja LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E-GRsahrSlKw",
      "metadata": {
        "id": "E-GRsahrSlKw"
      },
      "source": [
        "#**PENGERJAAN TUGAS**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 2 - LSTM & Embeded Trainable GloVe (Pre-Train)"
      ],
      "metadata": {
        "id": "vfrT6qguTtN4"
      },
      "id": "vfrT6qguTtN4"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb4a6dbd",
      "metadata": {
        "id": "fb4a6dbd"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "\n",
        "Diceritakan terdapat seekor kancil yang sombong karena kemampuan berlarinya dan mengajak kura-kura untuk melakukan lomba lari dengannya.\n",
        "Dengan rendah hati dan percaya diri, kura-kura pun menerima ajakan kancil.\n",
        "Keesokan paginya, keduanya menuju kawasan hutan tempat lomba lari.\n",
        "Sesuai dengan perkiraan si kancil, ia berhasil lari dengan sangat cepat dan mengalahkan kura-kura yang tertinggal di belakang.\n",
        "Namun, ketika kancil mendekati garis finish, ia memutuskan untuk istirahat di bawah pohon rindang karena beranggapan bahwa\n",
        "lawannya itu masih sangat lama tiba. Sampai akhirnya si kancil tertidur pulas dan tidak menyadari bahwa kura-kura telah lebih dulu\n",
        "sampai digaris finish. Dari dongeng di atas, pesan moral yang bisa diajarkan pada si Kecil adalah untuk tetap rendah diri mau sehebat apapun dirinya.\n",
        "Selain itu, anak juga diajarkan untuk tidak meremehkan kemampuan orang lain dengan kemampuannya.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c2d6271d",
      "metadata": {
        "id": "c2d6271d"
      },
      "outputs": [],
      "source": [
        "# Impor Tokenizer untuk memproses teks menjadi token\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Impor pad_sequences untuk mempadatkan sequence token menjadi panjang yang sama\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Impor library numpy untuk operasi numerik\n",
        "import numpy as np\n",
        "\n",
        "# Impor library tensorflow untuk membangun model deep learning\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "qIyH_ii1f5fw",
      "metadata": {
        "id": "qIyH_ii1f5fw"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer() # Buat objek Tokenizer untuk memproses teks\n",
        "tokenizer.fit_on_texts([text]) # Sesuaikan tokenizer dengan teks yang diberikan\n",
        "sequences = tokenizer.texts_to_sequences([text])[0] # Ubah teks menjadi sequence token\n",
        "\n",
        "# Inisialisasi list untuk menyimpan data X dan y\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(1, len(sequences)): # Buat data X dan y dengan cara memisahkan sequence token\n",
        "    X.append(sequences[:i])  # X adalah sequence token hingga indeks i\n",
        "    y.append(sequences[i])     # y adalah token berikutnya setelah indeks i\n",
        "\n",
        "X = pad_sequences(X) # Padatkan sequence X menjadi panjang yang sama\n",
        "y = np.array(y) # Ubah y menjadi array numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e3d42794",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3d42794",
        "outputId": "2b954032-406f-4e9a-8bdf-9cdd4ab40cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-04 03:08:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-05-04 03:08:31--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-05-04 03:08:31--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2025-05-04 03:11:10 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B/glove.6B.50d.txt  \n",
            "  inflating: glove.6B/glove.6B.100d.txt  \n",
            "  inflating: glove.6B/glove.6B.200d.txt  \n",
            "  inflating: glove.6B/glove.6B.300d.txt  \n",
            "Loaded 400000 word vectors from GloVe.\n"
          ]
        }
      ],
      "source": [
        "# Unduh GloVe jika belum ada (gunakan 100 dimensi untuk keseimbangan performa dan akurasi)\n",
        "!wget -nc http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -n glove.6B.zip -d glove.6B\n",
        "\n",
        "# Muat vektor GloVe\n",
        "embeddings_index = {}\n",
        "\n",
        "with open(\"glove.6B/glove.6B.100d.txt\", encoding='utf-8') as f: # Buka file glove.6B.100d.txt yang berisi vektor GloVe\n",
        "    for line in f: # Iterasi setiap baris dalam file\n",
        "        values = line.split() # Pisahkan nilai-nilai dalam baris menjadi kata dan vektor\n",
        "        word = values[0] # Kata adalah nilai pertama dalam baris\n",
        "        coefs = np.asarray(values[1:], dtype='float32')  # Vektor adalah nilai-nilai setelah kata\n",
        "        embeddings_index[word] = coefs # Simpan vektor kata dalam dictionary embeddings_index\n",
        "\n",
        "print(f\"Loaded {len(embeddings_index)} word vectors from GloVe.\") # Cetak jumlah vektor kata yang telah dimuat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "63d7f85c",
      "metadata": {
        "id": "63d7f85c"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100  # Tentukan dimensi embedding yang digunakan\n",
        "word_index = tokenizer.word_index  # Dapatkan word_index dari tokenizer\n",
        "num_words = len(word_index) + 1  # Hitung jumlah kata yang ada dalam word_index\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))  # Buat matriks embedding\n",
        "\n",
        "for word, i in word_index.items():  # Iterasi setiap kata dalam word_index\n",
        "    embedding_vector = embeddings_index.get(word)  # Cari vektor embedding untuk kata tersebut\n",
        "    if embedding_vector is not None:  # Jika vektor embedding ditemukan\n",
        "        embedding_matrix[i] = embedding_vector  # Masukkan ke dalam matriks embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f9d86616",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "f9d86616",
        "outputId": "443f9072-047e-49a6-a611-6c0fb7bac5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │         \u001b[38;5;34m9,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,300\u001b[0m (36.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,300</span> (36.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,300\u001b[0m (36.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,300</span> (36.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential  # Impor model Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense  # Impor lapisan Embedding, LSTM, dan Dense\n",
        "\n",
        "max_sequence_len = X.shape[1]  # Hitung panjang maksimum sequence\n",
        "\n",
        "model = Sequential()  # Buat model Sequential\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_sequence_len - 1,\n",
        "                    trainable=True))  # Tambahkan lapisan Embedding\n",
        "\n",
        "model.add(LSTM(100))  # Tambahkan lapisan LSTM\n",
        "model.add(Dense(num_words, activation='softmax'))  # Tambahkan lapisan Dense dengan aktivasi softmax\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Kompilasi model dengan loss categorical_crossentropy dan optimizer adam\n",
        "model.summary()  # Cetak ringkasan model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "JFT0NxWngRIw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFT0NxWngRIw",
        "outputId": "5afc6acc-58e2-4d1f-aa40-9cb90931d1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.0064 - loss: 4.5408\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.0454 - loss: 4.4740\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.0561 - loss: 4.4171\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.0898 - loss: 4.3497\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.0729 - loss: 4.2797\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0843 - loss: 4.1930\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.0671 - loss: 4.0779\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.0695 - loss: 3.9990\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.1589 - loss: 3.8486\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.1795 - loss: 3.7483\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.1729 - loss: 3.6624\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2588 - loss: 3.4709\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.2760 - loss: 3.2515\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.2846 - loss: 3.1975\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2840 - loss: 3.1185\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2995 - loss: 3.0396\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.2845 - loss: 2.9085\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.3477 - loss: 2.7352\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - accuracy: 0.3610 - loss: 2.6871\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.3855 - loss: 2.4838\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.3956 - loss: 2.4029\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4155 - loss: 2.3670\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5188 - loss: 2.2193\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5232 - loss: 2.1525\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.5400 - loss: 2.0641\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.5856 - loss: 1.9736\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.5739 - loss: 1.9565\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.5186 - loss: 1.9212\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5784 - loss: 1.7944\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.5855 - loss: 1.7545\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.6126 - loss: 1.6604\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.5949 - loss: 1.6433\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.6450 - loss: 1.5971\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.6801 - loss: 1.5499\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.6248 - loss: 1.5159\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7362 - loss: 1.4187\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.7280 - loss: 1.3865\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.6478 - loss: 1.4610\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.7393 - loss: 1.3190\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.6676 - loss: 1.3431\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.7586 - loss: 1.2884\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8026 - loss: 1.1930\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.7974 - loss: 1.1794\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7436 - loss: 1.1937\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.7803 - loss: 1.1260\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.7997 - loss: 1.1286\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.8045 - loss: 1.0816\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8101 - loss: 1.0481\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8448 - loss: 1.0531\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8725 - loss: 0.9710\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8469 - loss: 0.9906\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.8786 - loss: 0.9563\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.8922 - loss: 0.9268\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8866 - loss: 0.9171\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8797 - loss: 0.9042\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9037 - loss: 0.8678\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9063 - loss: 0.8519\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9220 - loss: 0.8498\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9129 - loss: 0.7873\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.9244 - loss: 0.8048\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.9301 - loss: 0.7686\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 0.9409 - loss: 0.7784\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - accuracy: 0.9227 - loss: 0.7562\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9468 - loss: 0.7517\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9356 - loss: 0.7361\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9480 - loss: 0.6989\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9564 - loss: 0.6772\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9476 - loss: 0.6705\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9501 - loss: 0.6517\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9493 - loss: 0.6519\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9433 - loss: 0.6380\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9468 - loss: 0.6223\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9148 - loss: 0.6484\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9658 - loss: 0.6006\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9274 - loss: 0.5977\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9485 - loss: 0.5595\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9420 - loss: 0.5957\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9781 - loss: 0.5545\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9718 - loss: 0.5257\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9437 - loss: 0.5479\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9352 - loss: 0.5327\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.9437 - loss: 0.5145\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.9567 - loss: 0.5000\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 0.9350 - loss: 0.4985\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - accuracy: 0.9691 - loss: 0.4994\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9595 - loss: 0.4870\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9409 - loss: 0.4970\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9673 - loss: 0.4607\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9772 - loss: 0.4437\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9708 - loss: 0.4491\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9652 - loss: 0.4410\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9757 - loss: 0.4306\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9804 - loss: 0.4125\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9746 - loss: 0.4126\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9595 - loss: 0.4159\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9842 - loss: 0.4077\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9785 - loss: 0.3979\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9798 - loss: 0.4059\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9822 - loss: 0.3737\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9893 - loss: 0.3710\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f924356b310>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import tensorflow as tf  # Impor library tensorflow\n",
        "\n",
        "num_words = len(tokenizer.word_index) + 1  # Hitung jumlah kata unik\n",
        "y = np.array(y)  # Ubah y menjadi array numpy\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=num_words)  # Ubah y menjadi bentuk kategorikal\n",
        "model.fit(X, y, epochs=100, verbose=1)  # Latih model dengan data X dan y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "izqH37lRD4GE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izqH37lRD4GE",
        "outputId": "5d9d7ae0-9304-4c40-adf5-dfd8da8ac1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi kata berikutnya: terdapat\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Diceritakan\"  # Teks awal untuk prediksi\n",
        "tokens = tokenizer.texts_to_sequences([seed_text])[0]  # Ubah teks menjadi sequence token\n",
        "tokens = pad_sequences([tokens], maxlen=X.shape[1])  # Padatkan sequence token\n",
        "predicted = model.predict(tokens, verbose=0)  # Prediksi kata berikutnya\n",
        "predicted_word_index = np.argmax(predicted)  # Dapatkan indeks kata yang diprediksi\n",
        "\n",
        "# Cari kata yang sesuai dengan indeks yang diprediksi\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "        print(\"Prediksi kata berikutnya:\", word)  # Cetak kata yang diprediksi\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SPTkzHyjJJfB",
      "metadata": {
        "id": "SPTkzHyjJJfB"
      },
      "source": [
        "Hasil prediksinya adalah ```terdapat```, hasil prediksi tersebut *make sense* karena mengikuti text awalnya pada baris pertama cerita ini, \"Diceritakan ```terdapat```...\" walaupun text input hanya 1 kata. Sengaja text input menggunakan huruf kapital, mungkin ini memengaruhi model untuk memahami urutan waktu pada LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d78da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66d78da1",
        "outputId": "5f06dda5-2127-40c2-ab51-6d3fe0eb293c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi kata berikutnya: sombong\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"seekor kancil yang\"  # Teks awal untuk prediksi\n",
        "tokens = tokenizer.texts_to_sequences([seed_text])[0]  # Ubah teks menjadi sequence token\n",
        "tokens = pad_sequences([tokens], maxlen=X.shape[1])  # Padatkan sequence token\n",
        "predicted = model.predict(tokens, verbose=0)  # Prediksi kata berikutnya\n",
        "predicted_word_index = np.argmax(predicted)  # Dapatkan indeks kata yang diprediksi\n",
        "\n",
        "# Cari kata yang sesuai dengan indeks yang diprediksi\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "        print(\"Prediksi kata berikutnya:\", word)  # Cetak kata yang diprediksi\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VGXXrXo5JnyK",
      "metadata": {
        "id": "VGXXrXo5JnyK"
      },
      "source": [
        "Hasil prediksinya adalah ```sombong```, hasil prediksi tersebut *make sense* karena mengikuti text awalnya pada baris pertama cerita ini, \"Diceritakan terdapat seekor kancil ```sombong```...\" text input terdiri atas 3 kata. Sengaja text input tidak menggunakan huruf kapital, mungkin ini memengaruhi model untuk memahami urutan waktu pada LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I1MtaKmWHyM_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1MtaKmWHyM_",
        "outputId": "9da122f6-3949-4368-fe86-99068bb4a912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi kata berikutnya: mengajak\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"karena kemampuan berlarinya dan\"  # Teks awal untuk prediksi\n",
        "tokens = tokenizer.texts_to_sequences([seed_text])[0]  # Ubah teks menjadi sequence token\n",
        "tokens = pad_sequences([tokens], maxlen=X.shape[1])  # Padatkan sequence token\n",
        "predicted = model.predict(tokens, verbose=0)  # Prediksi kata berikutnya\n",
        "predicted_word_index = np.argmax(predicted)  # Dapatkan indeks kata yang diprediksi\n",
        "\n",
        "# Cari kata yang sesuai dengan indeks yang diprediksi\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "        print(\"Prediksi kata berikutnya:\", word)  # Cetak kata yang diprediksi\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xi-bYR9cKRXt",
      "metadata": {
        "id": "xi-bYR9cKRXt"
      },
      "source": [
        "Hasil prediksinya adalah ```mengajak```, hasil prediksi tersebut *make sense* karena mengikuti text awalnya pada baris pertama cerita ini, \"Diceritakan terdapat seekor kancil yang sombong karena kemampuan berlarinya dan ``` mengajak``` kura-kura untuk melakukan lomba lari dengannya.\" text input terdiri atas 4 kata. Sengaja text input tidak menggunakan huruf kapital, mungkin ini memengaruhi model untuk memahami urutan waktu pada LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dav4lwNMIAXC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dav4lwNMIAXC",
        "outputId": "16c7d646-178b-4e74-f454-428cb8bdbb90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi kata berikutnya: lari\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"kura-kura untuk melakukan lomba\"  # Teks awal untuk prediksi\n",
        "tokens = tokenizer.texts_to_sequences([seed_text])[0]  # Ubah teks menjadi sequence token\n",
        "tokens = pad_sequences([tokens], maxlen=X.shape[1])  # Padatkan sequence token\n",
        "predicted = model.predict(tokens, verbose=0)  # Prediksi kata berikutnya\n",
        "predicted_word_index = np.argmax(predicted)  # Dapatkan indeks kata yang diprediksi\n",
        "\n",
        "# Cari kata yang sesuai dengan indeks yang diprediksi\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "        print(\"Prediksi kata berikutnya:\", word)  # Cetak kata yang diprediksi\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zF7j6ix-K084",
      "metadata": {
        "id": "zF7j6ix-K084"
      },
      "source": [
        "Hasil prediksinya adalah ```lari```, hasil prediksi tersebut *make sense* karena mengikuti text awalnya pada baris pertama cerita ini, \"Diceritakan terdapat seekor kancil yang sombong karena kemampuan berlarinya dan mengajak  kura-kura untuk melakukan lomba ```lari``` dengannya.\" text input terdiri atas 5 kata. Sengaja text input tidak menggunakan huruf kapital, mungkin ini memengaruhi model untuk memahami urutan waktu pada LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bi3Gkkj_ILYO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi3Gkkj_ILYO",
        "outputId": "f939ac6b-0b6a-4383-d3b9-1fde0d73ba6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi kata berikutnya: kancil\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"lomba lari dengannya.\"  # Teks awal untuk prediksi\n",
        "tokens = tokenizer.texts_to_sequences([seed_text])[0]  # Ubah teks menjadi sequence token\n",
        "tokens = pad_sequences([tokens], maxlen=X.shape[1])  # Padatkan sequence token\n",
        "predicted = model.predict(tokens, verbose=0)  # Prediksi kata berikutnya\n",
        "predicted_word_index = np.argmax(predicted)  # Dapatkan indeks kata yang diprediksi\n",
        "\n",
        "# Cari kata yang sesuai dengan indeks yang diprediksi\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "        print(\"Prediksi kata berikutnya:\", word)  # Cetak kata yang diprediksi\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cphlRAZ7LHFw",
      "metadata": {
        "id": "cphlRAZ7LHFw"
      },
      "source": [
        "Hasil prediksinya adalah ```kancil```, hasil prediksi tersebut tidak *make sense* karena tidak mengikuti text awalnya pada baris kedua cerita ini, \"Diceritakan terdapat seekor kancil yang sombong karena kemampuan berlarinya dan mengajak  kura-kura untuk melakukan lomba lari dengannya.\" seharusnya kalimat selanjutnya adalah \"Dengan rendah hati dan percaya diri, kura-kura pun menerima ajakan kancil\" maka kata selanjutnya harusnya adalah \"dengan\", padahal text input sudah menggunakan kalimat lengkap pada text asli yang terdiri atas 3 kata namun model tidak mampu memprediksi dengan tepat kata selanjutnya. Sengaja text input tidak menggunakan huruf kapital, mungkin ini memengaruhi model untuk memahami urutan waktu pada LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eh-Vk_E5Ibby",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh-Vk_E5Ibby",
        "outputId": "7f22b373-57d6-4e48-980c-530d05f98493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi kata berikutnya: kancil\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"dengan rendah hati\"  # Teks awal untuk prediksi\n",
        "tokens = tokenizer.texts_to_sequences([seed_text])[0]  # Ubah teks menjadi sequence token\n",
        "tokens = pad_sequences([tokens], maxlen=X.shape[1])  # Padatkan sequence token\n",
        "predicted = model.predict(tokens, verbose=0)  # Prediksi kata berikutnya\n",
        "predicted_word_index = np.argmax(predicted)  # Dapatkan indeks kata yang diprediksi\n",
        "\n",
        "# Cari kata yang sesuai dengan indeks yang diprediksi\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "        print(\"Prediksi kata berikutnya:\", word)  # Cetak kata yang diprediksi\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RY0Xa2HxM4Sm",
      "metadata": {
        "id": "RY0Xa2HxM4Sm"
      },
      "source": [
        "Hasil prediksinya adalah ```kancil```, hasil prediksi tersebut tidak *make sense* karena tidak mengikuti text awalnya pada baris kedua cerita ini, \"Dengan rendah hati dan percaya diri, kura-kura pun menerima ajakan kancil\" maka kata selanjutnya harusnya adalah \"dan\", padahal text input sudah menggunakan kalimat lengkap pada text asli yang terdiri atas 3 kata namun model tidak mampu memprediksi dengan tepat kata selanjutnya. Sengaja text input tidak menggunakan huruf kapital, mungkin ini memengaruhi model untuk memahami urutan waktu pada LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WJoIbxo9IpIs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJoIbxo9IpIs",
        "outputId": "5cca2879-04aa-4709-fcce-0d36827df068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi kata berikutnya: kura\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Dengan rendah hati dan percaya diri\"  # Teks awal untuk prediksi\n",
        "tokens = tokenizer.texts_to_sequences([seed_text])[0]  # Ubah teks menjadi sequence token\n",
        "tokens = pad_sequences([tokens], maxlen=X.shape[1])  # Padatkan sequence token\n",
        "predicted = model.predict(tokens, verbose=0)  # Prediksi kata berikutnya\n",
        "predicted_word_index = np.argmax(predicted)  # Dapatkan indeks kata yang diprediksi\n",
        "\n",
        "# Cari kata yang sesuai dengan indeks yang diprediksi\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "        print(\"Prediksi kata berikutnya:\", word)  # Cetak kata yang diprediksi\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "klVrFaoCNLjZ",
      "metadata": {
        "id": "klVrFaoCNLjZ"
      },
      "source": [
        "Hasil prediksinya adalah ```kura```, hasil prediksi tersebut *make sense* karena mengikuti text awalnya pada baris kedua cerita ini, \"Dengan rendah hati dan percaya diri, kura-kura pun menerima ajakan kancil\" maka kata selanjutnya harusnya adalah \"kura-kura\" atau \"kura\", dengan text input sudah menggunakan kalimat lengkap pada text asli yang terdiri atas 6 kata sehingga model mampu memprediksi dengan tepat kata selanjutnya. Sengaja text input tidak menggunakan huruf kapital, mungkin ini memengaruhi model untuk memahami urutan waktu pada LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluasi**\n",
        "\n",
        "Model LSTM yang saya bangun sebelumnya sebenarnya telah menunjukkan performa cukup baik dengan akurasi pelatihan mencapai 98%. Pada modifikasi model kedua, saya membuat perubahan penting dengan menjadikan layer *Embedding* bersifat *trainable*, sehingga bobot GloVe yang awalnya statis kini dapat ikut disesuaikan berdasarkan pola dalam dataset cerita anak yang saya gunakan. Ini memberi fleksibilitas lebih besar bagi model untuk menangkap nuansa semantik yang lebih khas. Struktur arsitektur LSTM dan Dense masih sama seperti model awal, namun karena bobot embedding kini dituning, hasil pelatihan menunjukkan peningkatan performa secara numerik. Meskipun begitu, saya mengamati bahwa prediksi kata berikutnya masih belum selalu konsisten atau bermakna, bahkan ketika input kalimat sudah sesuai urutan atau cukup panjang. Hal ini menyadarkan saya bahwa akurasi tinggi pada training tidak serta-merta mencerminkan kualitas generatif model—karena akurasi hanya mengukur kesesuaian prediksi terhadap kata target, bukan kelogisan dan kesinambungan kalimat secara menyeluruh. Salah satu penyebab lain kemungkinan adalah distribusi kata dalam dataset yang tidak merata; kata-kata umum seperti “dan”, “yang”, atau “di” cenderung mendominasi dan bisa menyebabkan model terlalu sering memilih kata-kata tersebut tanpa mempertimbangkan konteks. Selain itu, model masih sederhana, tanpa penambahan *dropout* atau *stacked LSTM* yang bisa membantu menghindari overfitting dan meningkatkan generalisasi. Berdasarkan evaluasi tersebut, saya memutuskan membangun model ketiga yang tetap mempertahankan struktur arsitektur LSTM dan *trainable* GloVe, namun kini ditambahkan metode prediksi *top-k sampling* sebagai strategi decoding. Modifikasi ini bertujuan agar model tidak hanya memilih kata dengan probabilitas tertinggi secara kaku, melainkan bisa mengeksplorasi beberapa kemungkinan kata teratas yang lebih kontekstual dan bervariasi, sehingga hasil prediksi kata berikutnya menjadi lebih alami dan bermakna."
      ],
      "metadata": {
        "id": "mmVKv7WaVy7o"
      },
      "id": "mmVKv7WaVy7o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 3 - LSTM, Pre-Train GloVe & Top k-Sampling (k=10, k=20)"
      ],
      "metadata": {
        "id": "fnaG9-2xV5ow"
      },
      "id": "fnaG9-2xV5ow"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model ini dibuat untuk prediksi kata yang lebih masuk akal dan alami saat generate kalimat."
      ],
      "metadata": {
        "id": "x0XUlz6sX_IB"
      },
      "id": "x0XUlz6sX_IB"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9a975bf3",
      "metadata": {
        "id": "9a975bf3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def predict_next_word_top_k(model, tokenizer, text_seq, k=20, max_len=10):\n",
        "    token_list = tokenizer.texts_to_sequences([text_seq])[0]\n",
        "    token_list = token_list[-max_len:]  # ambil bagian akhir sesuai panjang input\n",
        "    padded = pad_sequences([token_list], maxlen=max_len, padding='pre')\n",
        "\n",
        "    preds = model.predict(padded, verbose=0)[0]\n",
        "\n",
        "    # Ambil top-k kata dengan probabilitas tertinggi\n",
        "    top_k_indices = preds.argsort()[-k:][::-1]\n",
        "    top_k_probs = preds[top_k_indices]\n",
        "    top_k_probs = top_k_probs / top_k_probs.sum()  # normalisasi probabilitas\n",
        "\n",
        "    # Pilih satu kata dari top-k berdasarkan distribusi probabilitas\n",
        "    next_index = np.random.choice(top_k_indices, p=top_k_probs)\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == next_index:\n",
        "            return word\n",
        "    return \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "66eaf32e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66eaf32e",
        "outputId": "da54feee-7aa9-4c4b-d0a8-1f5564bcdbdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: dengan rendah hati kura kura pun menerima ajakan\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"dengan rendah hati\"\n",
        "generated = seed_text\n",
        "for _ in range(5):\n",
        "    next_word = predict_next_word_top_k(model, tokenizer, generated, k=5)\n",
        "    generated += \" \" + next_word\n",
        "print(\"Generated text:\", generated)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dengan menggunakan k= 10, didapatkan hasil yang sangat make sense namun masih ada kata-kata yang hilang berdasarkan teks asli yaitu seharusnya \"...dengan rendah hati dan percaya diri kura kura pun menerima ajakan...\". Namun hasilnya hanya \"dengan rendah hati kura kura pun menerima ajakan\" walaupun demikian, dengan k=10 output prediksi sudah samgat baik."
      ],
      "metadata": {
        "id": "MqMnDfmzSxWL"
      },
      "id": "MqMnDfmzSxWL"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Contoh penggunaan top-k sampling\n",
        "seed_text = \"dengan rendah hati\"\n",
        "generated = seed_text\n",
        "for _ in range(5):\n",
        "    next_word = predict_next_word_top_k(model, tokenizer, generated, k=5)\n",
        "    generated += \" \" + next_word\n",
        "print(\"Generated text:\", generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiwAtOs4Sr-V",
        "outputId": "eba14eb7-5df2-487b-aac2-4469f3d30995"
      },
      "id": "SiwAtOs4Sr-V",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: dengan rendah hati dan percaya kura kura pun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dengan tuning parameter k menjadi k=20 didapatkan hasil yang jauh lebih baik dan tepat daripada saat k=10 pada input text test sebelumnya. Karena dengan meningkatkan k maka model jadi jauh lebih kreatif."
      ],
      "metadata": {
        "id": "23WwZmJnTbQs"
      },
      "id": "23WwZmJnTbQs"
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"diceritakan\"\n",
        "generated = seed_text\n",
        "for _ in range(5):\n",
        "    next_word = predict_next_word_top_k(model, tokenizer, generated, k=5)\n",
        "    generated += \" \" + next_word\n",
        "print(\"Generated text:\", generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj2zAOkfSQRQ",
        "outputId": "e278b795-4df3-4241-a20f-443e44719f71"
      },
      "id": "xj2zAOkfSQRQ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: diceritakan terdapat terdapat seekor kancil yang\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output yang dihasilkan sudah tepat dengan text aslinya. Maka tuning parameter yang cukup akurat sejauh ini adalah menggunakan k=20 pada model prediksi."
      ],
      "metadata": {
        "id": "GPGR3UFEWaFJ"
      },
      "id": "GPGR3UFEWaFJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cara Kerja LSTM"
      ],
      "metadata": {
        "id": "WvL-SgG9YaYd"
      },
      "id": "WvL-SgG9YaYd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM (Long Short-Term Memory) adalah jenis jaringan saraf tiruan yang dirancang khusus untuk memproses data berurutan, seperti teks atau waktu. Cara kerja LSTM sederhana dimulai dengan menerima input berupa urutan kata yang telah diubah menjadi angka melalui proses tokenisasi. Setiap kata dalam urutan tersebut akan diproses satu per satu secara berurutan. LSTM memiliki tiga \"gerbang\" utama—*forget gate*, *input gate*, dan *output gate*—yang masing-masing bertugas mengatur informasi apa yang harus dibuang, disimpan, atau diteruskan ke langkah selanjutnya. *Forget gate* memutuskan informasi lama mana yang perlu dilupakan, *input gate* menentukan informasi baru apa yang layak disimpan, dan *output gate* menentukan apa yang akan dikeluarkan sebagai hasil di setiap langkah waktu. Keunggulan LSTM dibanding RNN biasa terletak pada kemampuannya mempertahankan informasi penting dalam *cell state* (memori internal) untuk waktu yang lebih lama, sehingga dapat mengingat konteks yang relevan meskipun kata-kata penting muncul jauh di awal kalimat. Setelah memproses seluruh urutan, keluaran terakhir dari LSTM biasanya diteruskan ke layer Dense (fully connected) yang menghasilkan prediksi, misalnya memprediksi kata selanjutnya dalam kalimat.\n"
      ],
      "metadata": {
        "id": "TXRY8QIDYcfR"
      },
      "id": "TXRY8QIDYcfR"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}